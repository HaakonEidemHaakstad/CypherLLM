Here is the updated `README.md` file. I have added the details regarding the attachment toggle feature in both the **Features** list and the **Usage Guide** section to accurately reflect the functionality present in the `index.html` code.

# CypherLLM

CypherLLM is a singleâ€‘page, local, multiâ€‘provider chat client for LLMs.  
It runs entirely in your browser and talks directly to OpenAI, Google Gemini, Anthropic Claude, xAI Grok, DeepSeek, Perplexity, and Mistral using your own API keys.

> No backend, no build step â€“ just open `index.html` with a static server and start chatting.

---

## Features

- **Multiâ€‘provider support**
  - OpenAI: `gpt-5.1`, `gpt-5.1-mini`
  - Google: `gemini-3-pro-preview`, `gemini-flash-latest`, `gemini-flash-lite-latest`
  - Anthropic: `claude-opus-4-5-20251101`, `claude-sonnet-4-5`, `claude-haiku-4-5`
  - xAI: `grok-4-latest`
  - DeepSeek: `deepseek-chat`, `deepseek-reasoner`, `deepseek-coder`
  - Perplexity: `sonar`, `sonar-pro`, `sonar-reasoning`, `sonar-deep-research`
  - Mistral: `codestral-latest`, `mistral-large-latest`, `mistral-medium-latest`, `mistral-small-latest`
- **Providerâ€‘specific controls**
  - OpenAI GPTâ€‘5: reasoning effort + verbosity controls
  - Other models: temperature control
- **Rich conversation management**
  - Pagination (newer/older) with configurable page size
  - â€œContext limitâ€ for how many prior pairs are sent with each request
  - Perâ€‘pair â€œInclude in contextâ€ toggle
  - Perâ€‘pair **Pin to context** (always included, doesnâ€™t count toward history limit)
  - Collapse/expand whole prompt/response pairs
  - Delete pairs, retry prompt (reâ€‘ask same user message)
- **System prompt & context view**
  - Editable global system prompt, saved in `localStorage`
  - Settings view showing:
    - Pinned context pairs
    - Active context pairs (paginated & respecting context limit)
- **Attachments**
  - Attach one or more local files (text only; read in browser)
  - **Toggle inclusion**: Click an attachment chip to include/exclude it from the context (visualized by opacity)
  - Content is injected into a system message as `[FILE n]` references
  - â€œRefreshâ€ menu to reâ€‘read files from disk (e.g., after edits)
- **Chat persistence**
  - Automatic saving of:
    - Conversation pairs
    - Attachments (text content + inclusion state)
    - System prompt
    - Chat name
    - Provider, model, and UI settings
  - Export conversation as JSON (with attachments + metadata)
  - Import conversation from JSON
  - â€œNew chatâ€ with unsavedâ€‘changes guard
- **API key management**
  - Perâ€‘provider API keys stored in `localStorage`
  - Inâ€‘app **API key modal** with:
    - Show/hide key
    - Clear key
    - Live validation against each providerâ€™s API
  - API key status indicator in header
- **UI niceties**
  - Customizable user avatar and perâ€‘provider assistant avatars (click avatar to upload)
  - Markdown rendering via [marked](https://github.com/markedjs/marked)
  - Syntax highlighting via [highlight.js](https://highlightjs.org/) (GitHub Dark theme)
  - Code blocks with:
    - Header/footer bars
    - Copy buttons (top and bottom)
    - Collapse/expand toggle
  - â€œThinkingâ€¦â€ indicator with animated dots + live timer
  - Backâ€‘toâ€‘top floating button
  - Chat name field + quick Save/Load buttons

---

## Getting Started

### 1. Clone or download

Place `index.html` (and optionally `LICENSE`) into a folder, or clone the repo if youâ€™ve set one up.

### 2. Run a simple static server

Opening `index.html` via `file://` may cause CORS issues for API calls.  
Use any static HTTP server, e.g.:

```bash
# Python 3
python -m http.server 8000

# Node (http-server)
npx http-server . -p 8000
```

Then open:

```text
http://localhost:8000/index.html
```

in a modern browser (Chrome/Edge/Firefox).

### 3. Set API keys

1. Choose a **Provider** (topâ€‘right dropdown).
2. Click the **key icon (ðŸ”‘)**.
3. Paste your API key (obtain from:  
   [OpenAI](https://platform.openai.com/account/api-keys) Â·
   [Google AI Studio](https://aistudio.google.com/app/apikey) Â·
   [Anthropic](https://console.anthropic.com/settings/keys) Â·
   [xAI](https://console.x.ai) Â·
   [DeepSeek](https://platform.deepseek.com) Â·
   [Perplexity](https://www.perplexity.ai/settings/api) Â·
   [Mistral](https://console.mistral.ai/))
4. Click **Save** â€“ the app will validate it against the provider.
5. Repeat for other providers as needed.

> Keys are stored in your browserâ€™s `localStorage` and sent directly from your browser to the provider APIs.  
> **Do not** use this with keys you consider highly sensitive on untrusted machines.

---

## Usage Guide

### Basic chat

1. Select **Provider** and **Model**.
2. (Optional) Adjust **Reasoning/Verbosity** (GPTâ€‘5) or **Temperature**.
3. Type into the **message box**.
4. Press **Enter** to send (Shift+Enter for a new line).

The app shows a temporary â€œThinkingâ€¦â€ assistant bubble with a live elapsedâ€‘time counter during each request.

### System prompt & context

- Click **âš™ Context** to open the **Context Settings** panel.
- **System Prompt / Context**:
  - Global instructions sent with every request.
  - Autoâ€‘saved to `localStorage`.
- **Pinned Context Pairs**:
  - Pairs you marked as **ðŸ“Œ Pin to context** in the main view.
  - Always included in context, do not count toward the history limit.
- **Active Context Pairs**:
  - Nonâ€‘pinned pairs currently included in context.
  - Paginated; respects **Context limit** from the top chat toolbar.

### Perâ€‘pair controls (main chat view)

For each prompt/response pair:

- **Include in context**: whether to send this pair in future requests.
- **ðŸ“Œ Pin to context**: move the pair to the â€œpinnedâ€ list (always included).
- **Retry prompt**: reâ€‘send the same user message as a fresh request (using current provider/model/settings).
- **Delete pair**: permanently remove the pair.
- **Collapse pair**: hides the full texts into a oneâ€‘line summary.

Assistant messages also have a **Copy response** button.

### Pagination & limits

- **Newer / Older**: navigate through pages of pairs.
- **Per page**: how many pairs to display per page.
- **Context limit**:
  - `0` = unlimited (all included nonâ€‘pinned pairs).
  - `>0` = number of most recent included nonâ€‘pinned pairs to send.

Pinned pairs are always sent, regardless of the context limit.

### Attachments

- Click **ðŸ“„** near the input box to attach files.
- Files are read as text and listed as chips under the input.
- Content is injected into a system message as `[FILE 1]`, `[FILE 2]`, etc.
- You can:
  - **Toggle inclusion**: Click the file chip to enable/disable sending that specific file (dimmed = excluded).
  - Remove attachments (Ã— on each chip).
  - Click **ðŸ“„ â†»** to open the **Refresh** dropdown:
    - Select which files to refresh.
    - Reâ€‘read them from disk (useful after editing locally).

> Note: only the *content* (not the original File objects) is persisted in `localStorage`.  
> After a browser restart, you may need to reâ€‘attach files to enable the refresh feature.

### Saving / Loading conversations

- **Chat name**: a short label stored with the conversation in `localStorage`.
- **Save**:
  - Exports JSON containing:
    - All pairs
    - Attachmentsâ€™ text content and inclusion state
    - Provider/model used
    - System prompt & chat name
- **Load**:
  - Imports a previously exported JSON file.
  - Replaces current conversation (with unsavedâ€‘changes warning).
- **New**:
  - Clears conversation, attachments, chat name, and context (with unsavedâ€‘changes warning).
  - Keeps provider/model and API keys.

---

## Implementation Notes

- Pure HTML/CSS/JS.
- External libs via CDN:
  - `marked` for Markdown parsing.
  - `highlight.js` (GitHub Dark theme) for syntax highlighting.
- All state (conversation, attachments, prompts, settings, avatars, API keys) is stored in `localStorage`.
- API calls:
  - **OpenAI**: `POST https://api.openai.com/v1/responses`  
    - Uses `reasoning` and `text.verbosity` for GPTâ€‘5.  
    - Optionally enables `web_search_preview` tool.
  - **Google**: `POST https://generativelanguage.googleapis.com/v1beta/models/*:generateContent`  
    - Uses `google_search` (for certain stable models) and `code_execution` tools where available.
  - **Anthropic**: `POST https://api.anthropic.com/v1/messages`  
    - Uses beta tool APIs (`web_search`, `computer`, `bash`, `text_editor`) with appropriate headers.
  - **xAI**: `POST https://api.x.ai/v1/chat/completions`.
  - **DeepSeek**: `POST https://api.deepseek.com/v1/chat/completions`  
    - OpenAIâ€‘compatible Chat Completions format.
  - **Perplexity**: `POST https://api.perplexity.ai/chat/completions`  
    - OpenAIâ€‘compatible Chat Completions format (Sonar models with webâ€‘grounded answers).
  - **Mistral**: `POST https://api.mistral.ai/v1/chat/completions`  
    - OpenAIâ€‘compatible Chat Completions format.

You may want to audit/adjust the model IDs, tool configurations, and headers as providers evolve.

### Extending with New Models/Providers

To add a new LLM provider or model to the CypherLLM UI, follow the stepâ€‘byâ€‘step recipe in [`ADD_MODEL_SYSTEM_PROMPT.md`](./ADD_MODEL_SYSTEM_PROMPT.md).

That document:

- Lists all the places in `index.html` that need to be updated (provider dropdown, model lists, API key storage, avatars, validation logic, etc.).
- Includes example code snippets for each step (e.g., how to wire up a new providerâ€™s API endpoint and headers).
- Is written so that **either a human developer or an LLM** (acting as a code assistant) can mechanically apply all required changes without missing any of the scattered integration points.

Use it whenever:

- You want to add a brandâ€‘new provider.
- You want to add or rename models for an existing provider.
- You need to update authentication, endpoints, or validation logic for a provider.

---

## Security Considerations

- API keys are stored in plain text in `localStorage` and used directly in browserâ€‘side `fetch` calls.
- Anyone with access to your browser profile can potentially retrieve your keys.
- Use this tool only on **trusted machines** and with **keys you are comfortable exposing to the browser**.

For production or shared environments, consider moving API calls to a backend service and removing direct key usage in the browser.

---

## Troubleshooting

- **API errors**: Ensure your API key is valid (check the status indicator). Some models/tools may require specific beta access or billing enabled on your account.
- **CORS issues**: Always run via a local HTTP server, not `file://`.
- **File refresh not working**: After import or restart, reâ€‘attach files to enable the refresh feature (original File objects aren't persisted).
- **Performance**: Large conversations or attachments may slow down the browser due to `localStorage` limits (~5MB). Export and start new chats periodically.
- **Browser compatibility**: Tested on Chrome 120+, Firefox 120+, Edge 120+. May not work on older browsers or Safari (due to `localStorage` and `fetch` behaviors).

If you encounter issues, check the browser console for errors and ensure your API credits are sufficient.

---

## License

This project is licensed under the MIT License.  
See [`LICENSE`](./LICENSE) for details.
